{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n714FyEdcaX"
      },
      "source": [
        "**Q1. Write a simple CUDA kernel that takes an array of integers and doubles each element.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nxLk8gLmcx1_",
        "outputId": "4f45be7b-c07a-49bd-d589-9455645ec949"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#include <iostream>\\n#include <cuda_runtime.h>\\n\\nusing namespace std;\\n\\n__global__ void add_basic()\\n{\\n    // COMPLETE THIS\\n}\\n\\nint main()\\n{\\n    // COMPLETE THIS\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "! touch add_basic.cu\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void add_basic()\n",
        "{\n",
        "    // COMPLETE THIS\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // COMPLETE THIS\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IFT0vwhdhKe"
      },
      "source": [
        "**Q2. Write a CUDA kernel to initialize an array of integers with the index value.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ozXZzwCsdhcu",
        "outputId": "b87935d6-3ed2-4d56-b3e7-12cd7bdd4973"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-9b6672ffd667>, line 6)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9b6672ffd667>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    using namespace std;\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "! touch add_basic.cu\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void initialize_array(int *array)\n",
        "{\n",
        "    // Calculate the index for the current thread\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "     // Initialize the array element at the calculated index with its index value\n",
        "    // Hint: Use the 'index' variable to assign the value\n",
        "    // COMPLETE THIS\n",
        "\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int array_size = 10;\n",
        "    int *d_array;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_array, array_size * sizeof(int));\n",
        "\n",
        "    // Launch the CUDA kernel to initialize the array\n",
        "    // Hint: Use the <<<...>>> syntax to specify the grid and block dimensions\n",
        "    // COMPLETE THIS\n",
        "\n",
        "    // Copy data from device to host\n",
        "    int h_array[array_size];\n",
        "    cudaMemcpy(h_array, d_array, array_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the initialized array\n",
        "    cout << \"Initialized Array:\" << endl;\n",
        "    for (int i = 0; i < array_size; ++i) {\n",
        "        cout << h_array[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_array);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uewwr30fg-R"
      },
      "source": [
        "**Q3 [OPTIONAL]. How do you check for and handle errors in CUDA API calls and kernel launches?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYdRBoA5fg1X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
